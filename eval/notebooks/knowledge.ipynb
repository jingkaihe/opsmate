{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge eval using the kubernetes website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opsmate.libs.knowledge import (\n",
    "    Runbook,\n",
    "    get_runbooks_table,\n",
    "    DatabaseConnection,\n",
    "    DocumentIngester,\n",
    ")\n",
    "from opsmate.libs.core.types import DocumentIngestion, DocumentIngestionSpec, Metadata\n",
    "from opsmate.libs.config import config\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "config.embeddings_db_path = \"./opsmate-embedding\"\n",
    "config.embedding_registry_name = \"openai\"\n",
    "config.embedding_model_name = \"text-embedding-3-small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d \"website\" ]; then\n",
    "    git clone git@github.com:kubernetes/website.git --depth=1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the kubernetes website data into the embedding database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-11-15 15:02:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mbatch ingest runbooks         \u001b[0m \u001b[36mbatch_size\u001b[0m=\u001b[35m97\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "runbook_table = get_runbooks_table()\n",
    "runbook_table.delete(\"1 = 1\")\n",
    "\n",
    "ingestion = DocumentIngestion(\n",
    "    metadata=Metadata(\n",
    "        name=\"k8s-concepts\",\n",
    "        description=\"Kubernetes Concepts\",\n",
    "    ),\n",
    "    spec=DocumentIngestionSpec(local_path=\"./website/content/en/docs/concepts/workloads/pods/*.md\"),\n",
    ")\n",
    "\n",
    "ingester = DocumentIngester()\n",
    "\n",
    "ingester.document_ingestion(ingestion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunbookChunk(uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', heading='', content='---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RunbookChunk(BaseModel):\n",
    "    uuid: str\n",
    "    heading: str\n",
    "    content: str\n",
    "\n",
    "runbook_table = get_runbooks_table()\n",
    "\n",
    "sample_runbooks = runbook_table.to_pandas()\n",
    "\n",
    "sample_chunks = [\n",
    "    RunbookChunk(\n",
    "        uuid=row[\"uuid\"],\n",
    "        heading=row[\"heading\"],\n",
    "        content=row[\"content\"],\n",
    "    )\n",
    "    for idx, row in sample_runbooks.iterrows()\n",
    "]\n",
    "\n",
    "sample_chunks[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some synthetic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='What are ephemeral containers used for in Kubernetes?', answer='Ephemeral containers are used to run temporarily in an existing pod to accomplish user-initiated actions such as troubleshooting.', uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', question_with_context='A user asked the following question:\\nQuestion: What are ephemeral containers used for in Kubernetes?\\nThis is about the following runbook:\\nRunbook Title: \\nRunbook Content: ---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->\\n'),\n",
       " ChunkEval(question='Can I use ephemeral containers to build applications?', answer='No, ephemeral containers are used to inspect services rather than to build applications.', uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', question_with_context='A user asked the following question:\\nQuestion: Can I use ephemeral containers to build applications?\\nThis is about the following runbook:\\nRunbook Title: \\nRunbook Content: ---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->\\n'),\n",
       " ChunkEval(question='What is the Kubernetes version that supports ephemeral containers?', answer='Ephemeral containers are stable starting from Kubernetes version v1.25.', uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', question_with_context='A user asked the following question:\\nQuestion: What is the Kubernetes version that supports ephemeral containers?\\nThis is about the following runbook:\\nRunbook Title: \\nRunbook Content: ---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "example_questions = [\n",
    "    \"How to create a pod?\",\n",
    "    \"How to scale a deployment from 1 replica to 3 replicas?\",\n",
    "]\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "class ChunkEval(QuestionAnswer):\n",
    "    uuid: str\n",
    "    question_with_context: str\n",
    "\n",
    "async def generate_evals(runbook: RunbookChunk, n_questions: int, example_questions: List[str]) -> List[ChunkEval]:\n",
    "    prompt = f\"\"\"\n",
    "Generate `{n_questions}` question-answer pairs about {runbook.heading}. The answer should primarily derived from the information in the runbook content.\n",
    "\n",
    "<content>\n",
    "{runbook.content}\n",
    "</content>\n",
    "\n",
    "Example questions:\n",
    "{\"\\n\".join('f - {q}' for q in example_questions)}\n",
    "\n",
    "Provide a concise and specific answer for each question.\n",
    "Do not use the exact example questions. Use them only as inspiration for the types of more specific questions to generate.\n",
    "Do not include answers that are not in the content.\n",
    "Questions should ask about how to do certain things and the answer should refer to how to do certain things based on the technical knowledge in the runbook.\n",
    "Stylistically, the questions should resemble what people would ask a RAG-based answer bot on a technical documentation website. So they can be a little informal, messy or scattered.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    def make_context(question: str) -> str:\n",
    "        return f\"\"\"A user asked the following question:\n",
    "Question: {question}\n",
    "This is about the following runbook:\n",
    "Runbook Title: {runbook.heading}\n",
    "Runbook Content: {runbook.content}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        pairs = client.chat.completions.create_iterable(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_model=QuestionAnswer,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "        return [\n",
    "            ChunkEval(\n",
    "                uuid=runbook.uuid,\n",
    "                heading=runbook.heading,\n",
    "                question=pair.question,\n",
    "                answer=pair.answer,\n",
    "                question_with_context=make_context(pair.question),\n",
    "            )\n",
    "            async for pair in pairs\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evals: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "first_chunk_res = await generate_evals(sample_chunks[0], 3, example_questions)\n",
    "first_chunk_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='What are ephemeral containers used for in Kubernetes?', answer='Ephemeral containers are used to run temporarily in an existing pod to accomplish user-initiated actions such as troubleshooting.', uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', question_with_context='A user asked the following question:\\nQuestion: What are ephemeral containers used for in Kubernetes?\\nThis is about the following runbook:\\nRunbook Title: \\nRunbook Content: ---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->\\n'),\n",
       " ChunkEval(question='Can I use ephemeral containers to build applications?', answer='No, ephemeral containers are used to inspect services rather than to build applications.', uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', question_with_context='A user asked the following question:\\nQuestion: Can I use ephemeral containers to build applications?\\nThis is about the following runbook:\\nRunbook Title: \\nRunbook Content: ---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->\\n'),\n",
       " ChunkEval(question='What is the Kubernetes version that supports ephemeral containers?', answer='Ephemeral containers are stable starting from Kubernetes version v1.25.', uuid='109e520d-5bc7-4bb5-9ea0-9bca5e39e52c', question_with_context='A user asked the following question:\\nQuestion: What is the Kubernetes version that supports ephemeral containers?\\nThis is about the following runbook:\\nRunbook Title: \\nRunbook Content: ---\\nreviewers:\\n- verb\\n- yujuhong\\ntitle: Ephemeral Containers\\ncontent_type: concept\\nweight: 60\\n---  \\n<!-- overview -->  \\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.25\" >}}  \\nThis page provides an overview of ephemeral containers: a special type of container\\nthat runs temporarily in an existing {{< glossary_tooltip term_id=\"pod\" >}} to\\naccomplish user-initiated actions such as troubleshooting. You use ephemeral\\ncontainers to inspect services rather than to build applications.  \\n<!-- body -->\\n')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "class ChunkProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "async def process_chunk(chunk: RunbookChunk, n_questions: int, example_questions: List[str], semaphore: asyncio.Semaphore) -> List[ChunkEval]:\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            return await generate_evals(chunk, n_questions, example_questions)\n",
    "        except Exception as e:\n",
    "            raise ChunkProcessingError(f\"Error processing chunk {chunk.id}: {str(e)}\") from e\n",
    "\n",
    "\n",
    "await process_chunk(sample_chunks[0], 3, example_questions, asyncio.Semaphore(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call `process_chunk` with all chunks to build the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import structlog\n",
    "import random\n",
    "\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "async def create_synthetic_dataset(\n",
    "    chunks: List[RunbookChunk],\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    max_workers: int = 10,\n",
    ") -> List[ChunkEval]:\n",
    "    semaphore = asyncio.Semaphore(max_workers)\n",
    "    tasks = [process_chunk(chunk, n_questions, example_questions, semaphore) for chunk in chunks]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    dataset = []\n",
    "    for result in results:\n",
    "        if isinstance(result, ChunkProcessingError):\n",
    "            print(f\"Error processing chunk: {result}\")\n",
    "        elif isinstance(result, list):\n",
    "            dataset.extend(result)\n",
    "        else:\n",
    "            print(f\"Unknown result type: {type(result)}\")\n",
    "    return dataset\n",
    "\n",
    "def save_eval_data(dataset: List[ChunkEval], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump([e.model_dump() for e in dataset], f, indent=2)\n",
    "\n",
    "def save_tf_data(dataset: List[ChunkEval], filename: str):\n",
    "    df = runbook_table.to_pandas()\n",
    "    with open(filename, \"w\") as f:\n",
    "        for chunk_eval in dataset:\n",
    "            content = chunk_eval.question\n",
    "            f.write(json.dumps({\n",
    "                \"query\": chunk_eval.question_with_context,\n",
    "                \"relevant_passages\": [content]\n",
    "            }) + \"\\n\")\n",
    "\n",
    "synthetic_dataset = await create_synthetic_dataset(sample_chunks, 3, example_questions)\n",
    "random.shuffle(synthetic_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 145 146\n",
      "\u001b[2m2024-11-15 15:04:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSynthetic eval dataset saved  \u001b[0m \u001b[36mdataset_len\u001b[0m=\u001b[35m291\u001b[0m \u001b[36meval_len\u001b[0m=\u001b[35m145\u001b[0m \u001b[36mft_len\u001b[0m=\u001b[35m146\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "split_idx = len(synthetic_dataset) // 2\n",
    "eval_dataset = synthetic_dataset[:split_idx]\n",
    "ft_dataset = synthetic_dataset[split_idx:]\n",
    "\n",
    "print(len(synthetic_dataset), len(eval_dataset), len(ft_dataset))\n",
    "save_eval_data(eval_dataset, \"synthetic_eval_dataset.json\")\n",
    "save_tf_data(ft_dataset, \"synthetic_ft_dataset.jsonl\")\n",
    "\n",
    "logger.info(\"Synthetic eval dataset saved\",\n",
    "    dataset_len=len(synthetic_dataset),\n",
    "    eval_len=len(eval_dataset),\n",
    "    ft_len=len(ft_dataset),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='Can I delay the scheduling of a Pod, and if so, how?', answer='Yes, you can use Pod Scheduling Readiness to delay scheduling for a Pod until all its scheduling gates are removed.', uuid='e655dc1b-3e0a-48ef-a6d3-0cebf97f6b18', question_with_context=\"A user asked the following question:\\nQuestion: Can I delay the scheduling of a Pod, and if so, how?\\nThis is about the following runbook:\\nRunbook Title: Pod lifetime\\nRunbook Content: Pod lifetimeWhilst a Pod is running, the kubelet is able to restart containers to handle some\\nkind of faults. Within a Pod, Kubernetes tracks different container\\n[states](#container-states) and determines what action to take to make the Pod\\nhealthy again.  \\nIn the Kubernetes API, Pods have both a specification and an actual status. The\\nstatus for a Pod object consists of a set of [Pod conditions](#pod-conditions).\\nYou can also inject [custom readiness information](#pod-readiness-gate) into the\\ncondition data for a Pod, if that is useful to your application.  \\nPods are only [scheduled](/docs/concepts/scheduling-eviction/) once in their lifetime;\\nassigning a Pod to a specific node is called _binding_, and the process of selecting\\nwhich node to use is called _scheduling_.\\nOnce a Pod has been scheduled and is bound to a node, Kubernetes tries\\nto run that Pod on the node. The Pod runs on that node until it stops, or until the Pod\\nis [terminated](#pod-termination); if Kubernetes isn't able to start the Pod on the selected\\nnode (for example, if the node crashes before the Pod starts), then that particular Pod\\nnever starts.  \\nYou can use [Pod Scheduling Readiness](/docs/concepts/scheduling-eviction/pod-scheduling-readiness/)\\nto delay scheduling for a Pod until all its _scheduling gates_ are removed. For example,\\nyou might want to define a set of Pods but only trigger scheduling once all the Pods\\nhave been created.\\n\"),\n",
       " ChunkEval(question='What are the key differences in resource handling between init containers and regular containers?', answer='The resource requests and limits for an init container are handled differently compared to regular containers.', uuid='9d40f6d7-c7a5-4e19-9f65-da71863a4bfd', question_with_context=\"A user asked the following question:\\nQuestion: What are the key differences in resource handling between init containers and regular containers?\\nThis is about the following runbook:\\nRunbook Title: Differences from regular containers\\nRunbook Content: Understanding init containersDifferences from regular containersInit containers support all the fields and features of app containers,\\nincluding resource limits, [volumes](/docs/concepts/storage/volumes/), and security settings. However, the\\nresource requests and limits for an init container are handled differently,\\nas documented in [Resource sharing within containers](#resource-sharing-within-containers).  \\nRegular init containers (in other words: excluding sidecar containers) do not support the\\n`lifecycle`, `livenessProbe`, `readinessProbe`, or `startupProbe` fields. Init containers\\nmust run to completion before the Pod can be ready; sidecar containers continue running\\nduring a Pod's lifetime, and _do_ support some probes. See [sidecar container](/docs/concepts/workloads/pods/sidecar-containers/)\\nfor further details about sidecar containers.  \\nIf you specify multiple init containers for a Pod, kubelet runs each init\\ncontainer sequentially. Each init container must succeed before the next can run.\\nWhen all of the init containers have run to completion, kubelet initializes\\nthe application containers for the Pod and runs them as usual.\\n\"),\n",
       " ChunkEval(question='What happens to Burstable Pods during Node resource pressure?', answer='Burstable Pods are evicted only after all BestEffort Pods are evicted in the event of Node resource pressure.', uuid='a0d3b227-9feb-4c48-ad9f-e26f5d033bdf', question_with_context='A user asked the following question:\\nQuestion: What happens to Burstable Pods during Node resource pressure?\\nThis is about the following runbook:\\nRunbook Title: Burstable\\nRunbook Content: Quality of Service classesBurstablePods that are `Burstable` have some lower-bound resource guarantees based on the request, but\\ndo not require a specific limit. If a limit is not specified, it defaults to a\\nlimit equivalent to the capacity of the Node, which allows the Pods to flexibly increase\\ntheir resources if resources are available. In the event of Pod eviction due to Node\\nresource pressure, these Pods are evicted only after all `BestEffort` Pods are evicted.\\nBecause a `Burstable` Pod can include a Container that has no resource limits or requests, a Pod\\nthat is `Burstable` can try to use any amount of node resources.  \\n#### Criteria  \\nA Pod is given a QoS class of `Burstable` if:  \\n* The Pod does not meet the criteria for QoS class `Guaranteed`.\\n* At least one Container in the Pod has a memory or CPU request or limit.\\n'),\n",
       " ChunkEval(question='What should I do if I need to debug init containers?', answer='To debug init containers, refer to the documentation on debugging applications specifically for init containers.', uuid='5168c12f-4d89-4f7b-b559-9db44f2c7967', question_with_context='A user asked the following question:\\nQuestion: What should I do if I need to debug init containers?\\nThis is about the following runbook:\\nRunbook Title: {{% heading \"whatsnext\" %}}\\nRunbook Content: {{% heading \"whatsnext\" %}}Learn more about the following:\\n* [Creating a Pod that has an init container](/docs/tasks/configure-pod-container/configure-pod-initialization/#create-a-pod-that-has-an-init-container).\\n* [Debug init containers](/docs/tasks/debug/debug-application/debug-init-containers/).\\n* Overview of [kubelet](/docs/reference/command-line-tools-reference/kubelet/) and [kubectl](/docs/reference/kubectl/).\\n* [Types of probes](/docs/concepts/workloads/pods/pod-lifecycle/#types-of-probe): liveness, readiness, startup probe.\\n* [Sidecar containers](/docs/concepts/workloads/pods/sidecar-containers).\\n'),\n",
       " ChunkEval(question='What are the benefits of using init containers for app deployment?', answer='Init containers allow the application image builder and deployer roles to work independently, enabling a more streamlined deployment process without the need to jointly build a single app image.', uuid='3efd3414-5f84-4013-8366-37aee1a85283', question_with_context='A user asked the following question:\\nQuestion: What are the benefits of using init containers for app deployment?\\nThis is about the following runbook:\\nRunbook Title: Using init containers\\nRunbook Content: Using init containersBecause init containers have separate images from app containers, they\\nhave some advantages for start-up related code:  \\n* Init containers can contain utilities or custom code for setup that are not present in an app\\nimage. For example, there is no need to make an image `FROM` another image just to use a tool like\\n`sed`, `awk`, `python`, or `dig` during setup.\\n* The application image builder and deployer roles can work independently without\\nthe need to jointly build a single app image.\\n* Init containers can run with a different view of the filesystem than app containers in the\\nsame Pod. Consequently, they can be given access to\\n{{< glossary_tooltip text=\"Secrets\" term_id=\"secret\" >}} that app containers cannot access.\\n* Because init containers run to completion before any app containers start, init containers offer\\na mechanism to block or delay app container startup until a set of preconditions are met. Once\\npreconditions are met, all of the app containers in a Pod can start in parallel.\\n* Init containers can securely run utilities or custom code that would otherwise make an app\\ncontainer image less secure. By keeping unnecessary tools separate you can limit the attack\\nsurface of your app container image.\\n')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"synthetic_eval_dataset.json\", \"r\") as f:\n",
    "    eval_dataset = json.load(f)\n",
    "\n",
    "eval_dataset_sample = eval_dataset[:5]\n",
    "\n",
    "eval_questions = [ChunkEval(**e) for e in eval_dataset_sample]\n",
    "\n",
    "eval_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_request(q: ChunkEval, n_return_vals=5):\n",
    "    results = (\n",
    "        runbook_table.search(q.question_with_context).select([\"id\"]).limit(n_return_vals).to_list()\n",
    "    )\n",
    "    return [str(q.uuid) == str(r[\"uuid\"]) for r in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(hits):\n",
    "    n_retrieval_requests = len(hits)\n",
    "    total_retrievals = sum(len(l) for l in hits)\n",
    "    true_positives = sum(sum(sublist) for sublist in hits)\n",
    "    precision = true_positives / total_retrievals if total_retrievals > 0 else 0\n",
    "    recall = true_positives / n_retrieval_requests if n_retrieval_requests > 0 else 0\n",
    "    return {\"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "LanceError(Schema): Column id does not exist, /home/runner/work/lance/lance/rust/lance-core/src/datatypes/schema.rs:190:31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score(hits)\n\u001b[1;32m     12\u001b[0m k_to_retrieve \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\u001b[43mscore_simple_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m k_to_retrieve])\n\u001b[1;32m     14\u001b[0m scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_retrieved\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m k_to_retrieve\n\u001b[1;32m     15\u001b[0m scores\n",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m, in \u001b[0;36mscore_simple_search\u001b[0;34m(n_to_retrieve)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_simple_search\u001b[39m(n_to_retrieve: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# parallelize to speed this up 5-10X\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m----> 7\u001b[0m         hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_simple_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_to_retrieve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_questions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score(hits)\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36mscore_simple_search.<locals>.<lambda>\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_simple_search\u001b[39m(n_to_retrieve: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# parallelize to speed this up 5-10X\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m      7\u001b[0m         hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m----> 8\u001b[0m             executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m q: \u001b[43mrun_simple_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_to_retrieve\u001b[49m\u001b[43m)\u001b[49m, eval_questions)\n\u001b[1;32m      9\u001b[0m         )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score(hits)\n",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m, in \u001b[0;36mrun_simple_request\u001b[0;34m(q, n_return_vals)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_simple_request\u001b[39m(q: ChunkEval, n_return_vals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      2\u001b[0m     results \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mrunbook_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion_with_context\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_return_vals\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(q\u001b[38;5;241m.\u001b[39mchunk_id) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/workspace/opsmate/.venv/lib/python3.12/site-packages/lancedb/query.py:333\u001b[0m, in \u001b[0;36mLanceQueryBuilder.to_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_list\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    Execute the query and return the results as a list of dictionaries.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m    fields are returned whether or not they're explicitly selected.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pylist()\n",
      "File \u001b[0;32m~/workspace/opsmate/.venv/lib/python3.12/site-packages/lancedb/query.py:662\u001b[0m, in \u001b[0;36mLanceVectorQueryBuilder.to_arrow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_arrow\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable:\n\u001b[1;32m    654\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m    Execute the query and return the results as an\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m    [Apache Arrow Table](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html#pyarrow.Table).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03m    vector and the returned vectors.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread_all()\n",
      "File \u001b[0;32m~/workspace/opsmate/.venv/lib/python3.12/site-packages/lancedb/query.py:694\u001b[0m, in \u001b[0;36mLanceVectorQueryBuilder.to_batches\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    679\u001b[0m     vector \u001b[38;5;241m=\u001b[39m [v\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vector]\n\u001b[1;32m    680\u001b[0m query \u001b[38;5;241m=\u001b[39m Query(\n\u001b[1;32m    681\u001b[0m     vector\u001b[38;5;241m=\u001b[39mvector,\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_where,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m     fast_search\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_search,\n\u001b[1;32m    693\u001b[0m )\n\u001b[0;32m--> 694\u001b[0m result_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reranker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     rs_table \u001b[38;5;241m=\u001b[39m result_set\u001b[38;5;241m.\u001b[39mread_all()\n",
      "File \u001b[0;32m~/workspace/opsmate/.venv/lib/python3.12/site-packages/lancedb/table.py:1892\u001b[0m, in \u001b[0;36mLanceTable._execute_query\u001b[0;34m(self, query, batch_size)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query\u001b[38;5;241m.\u001b[39mvector) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1884\u001b[0m     nearest \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1885\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m: query\u001b[38;5;241m.\u001b[39mvector_column,\n\u001b[1;32m   1886\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: query\u001b[38;5;241m.\u001b[39mvector,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefine_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m: query\u001b[38;5;241m.\u001b[39mrefine_factor,\n\u001b[1;32m   1891\u001b[0m     }\n\u001b[0;32m-> 1892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscanner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefilter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefilter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnearest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnearest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_text_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_text_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_row_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_row_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_reader()\n",
      "File \u001b[0;32m~/workspace/opsmate/.venv/lib/python3.12/site-packages/lance/dataset.py:389\u001b[0m, in \u001b[0;36mLanceDataset.scanner\u001b[0;34m(self, columns, filter, limit, offset, nearest, batch_size, batch_readahead, fragment_readahead, scan_in_order, fragments, full_text_query, prefilter, with_row_id, with_row_address, use_stats, fast_search, io_buffer_size, late_materialization, use_scalar_index)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nearest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     builder \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mnearest(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnearest)\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_scanner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/opsmate/.venv/lib/python3.12/site-packages/lance/dataset.py:2784\u001b[0m, in \u001b[0;36mScannerBuilder.to_scanner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_scanner\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LanceScanner:\n\u001b[0;32m-> 2784\u001b[0m     scanner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscanner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2785\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2786\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_columns_with_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2787\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2788\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefilter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2790\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2791\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nearest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2793\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io_buffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_readahead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fragment_readahead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_in_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2797\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fragments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_row_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_row_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2800\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_substrait_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_search\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_full_text_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_late_materialization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_scalar_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LanceScanner(scanner, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds)\n",
      "\u001b[0;31mValueError\u001b[0m: LanceError(Schema): Column id does not exist, /home/runner/work/lance/lance/rust/lance-core/src/datatypes/schema.rs:190:31"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict\n",
    "\n",
    "def score_simple_search(n_to_retrieve: List[int]) -> Dict[str, float]:\n",
    "    # parallelize to speed this up 5-10X\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        hits = list(\n",
    "            executor.map(lambda q: run_simple_request(q, n_to_retrieve), eval_questions)\n",
    "        )\n",
    "    return score(hits)\n",
    "\n",
    "k_to_retrieve = [5, 10]\n",
    "scores = pd.DataFrame([score_simple_search(n) for n in k_to_retrieve])\n",
    "scores[\"n_retrieved\"] = k_to_retrieve\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
